{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "font_size = 18\n",
    "ticks_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_data(srcind, tgtind, repo_path, dataset='tico19', model='towerinstruct13b', temperature=1.0, top_p=1.0, n_samples=50, split='dev', mbr=True):\n",
    "    if dataset=='tico19':\n",
    "        source_file=f\"{repo_path}results-{dataset}/{split}/{srcind}-{tgtind}/src.txt\"\n",
    "        target_file=f\"{repo_path}results-{dataset}/{split}/{srcind}-{tgtind}/ref.txt\"\n",
    "        output_file_dir=f\"{repo_path}results-{dataset}/{split}/{srcind}-{tgtind}\"\n",
    "        output_file=f\"{output_file_dir}/{model}-temp{temperature}-topp{top_p}-n{n_samples}\"\n",
    "        metrics_dir=f\"{repo_path}results-{dataset}/{split}/{srcind}-{tgtind}/metrics\"\n",
    "        metrics_segment=f\"{metrics_dir}/segment/{model}-temp{temperature}-topp{top_p}-n{n_samples}\"\n",
    "        if mbr:\n",
    "            mbr_matrices_path=f\"{output_file}-mbr-mbrmatrices\"\n",
    "\n",
    "    # get sources and targets\n",
    "    sources = [s.strip() for s in open(source_file, \"r\").readlines()]\n",
    "    targets = [s.strip() for s in open(target_file, \"r\").readlines()]\n",
    "\n",
    "    # get translations df\n",
    "    with open(output_file, encoding=\"utf-8\") as hyp_f:\n",
    "            hyps = [line.strip() for line in hyp_f.readlines()]\n",
    "    translations_df = pd.DataFrame(hyps)\n",
    "\n",
    "    # read metrics df\n",
    "    metrics_df = pd.read_csv(metrics_segment, sep=\" \")\n",
    "\n",
    "    # choose metric\n",
    "    metric='comet'\n",
    "\n",
    "    result = [num for num in range(len(sources)) for _ in range(n_samples)]\n",
    "    metrics_df['src_idx'] = result\n",
    "    \n",
    "    if mbr:\n",
    "        mbr_matrices = torch.load(mbr_matrices_path)\n",
    "        return metrics_df, sources, targets, translations_df, mbr_matrices\n",
    "\n",
    "    return metrics_df, sources, targets, translations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerankers(metrics_df, sources, n_samples, n_examples, metric='comet', critical_threshold=0.8):\n",
    "    # add n_sample for each example\n",
    "    aux_1 = np.arange(1, n_samples+1)\n",
    "    aux_2= np.tile(aux_1, n_examples)\n",
    "    metrics_df['n_sample'] = aux_2\n",
    "\n",
    "    # add critical errors\n",
    "    # the definition of critical error is always a threshold on COMET\n",
    "    metrics_df['critical'] = np.where(metrics_df['comet'] < critical_threshold, 1, 0)\n",
    "\n",
    "    critical_n_lbd = np.full((n_samples, n_examples), -1)\n",
    "    for K in range(1, n_samples+1):\n",
    "        # let's keep all translations up until the Kth one\n",
    "        selected_df = metrics_df[metrics_df['n_sample']<K+1]\n",
    "        \n",
    "        # let's have two modes: (1) reranking with comet, (2) reranking with cometkiwi, and (3) random reranker (keep always the K-th samples)\n",
    "        # these modes are dependent on 'metric'\n",
    "        # let's keep only the chosen translation for each example\n",
    "        if metric != 'random':\n",
    "            chosen_df = selected_df.loc[selected_df.groupby(selected_df.index // n_samples )[metric].idxmax()]\n",
    "        else:\n",
    "            chosen_df = metrics_df[metrics_df['n_sample'] == K]\n",
    "        critical_n_lbd[K-1] = np.array(chosen_df['critical'])\n",
    "\n",
    "    critical_absolute = critical_n_lbd.sum(axis=1)\n",
    "    critical_rate = critical_n_lbd.sum(axis=1)/len(sources)\n",
    "\n",
    "    return critical_rate, critical_n_lbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lps = True\n",
    "tgtinds = ['pt-BR', 'es-LA', 'ru']\n",
    "threshold_dev = 0.15\n",
    "threshold_devtest = threshold_dev\n",
    "srcind=\"en\"\n",
    "repo_path=\"\"\n",
    "temperature=1.0\n",
    "top_p=1.0\n",
    "n_samples=50\n",
    "dataset=\"tico19\"\n",
    "\n",
    "if merge_lps:\n",
    "    metrics_df_merged = pd.DataFrame()\n",
    "    test_metrics_df_merged = pd.DataFrame()\n",
    "    sources_merged = []\n",
    "    test_sources_merged  = []\n",
    "    mbr_matrices_merged = [[] for _ in range(n_samples)]\n",
    "    test_mbr_matrices_merged = [[] for _ in range(n_samples)]\n",
    "\n",
    "\n",
    "    for tgtind in tgtinds:\n",
    "        \n",
    "        split=\"dev\"\n",
    "        metrics_df, sources, _, _, mbr_matrices = get_calibration_data(srcind, tgtind, repo_path, dataset=dataset, model='towerinstruct13b', temperature=temperature, top_p=top_p, n_samples=n_samples, split=split, mbr=True)\n",
    "        metrics_df_merged = pd.concat([metrics_df_merged, metrics_df], ignore_index=True)\n",
    "        sources_merged.extend(sources)\n",
    "        for i, new_matrix in enumerate(mbr_matrices):\n",
    "            mbr_matrices_merged[i].extend(new_matrix)\n",
    "\n",
    "\n",
    "        split=\"test\"\n",
    "        test_metrics_df, test_sources, _, _, test_mbr_matrices = get_calibration_data(srcind, tgtind, repo_path, dataset=dataset, model='towerinstruct13b', temperature=temperature, top_p=top_p, n_samples=n_samples, split=split, mbr=True)\n",
    "        test_metrics_df_merged = pd.concat([test_metrics_df_merged, test_metrics_df], ignore_index=True)\n",
    "        test_sources_merged.extend(test_sources)\n",
    "        for i, new_matrix in enumerate(test_mbr_matrices):\n",
    "            test_mbr_matrices_merged[i].extend(new_matrix)\n",
    "        \n",
    "    result = [num for num in range(len(sources)*len(tgtinds)) for _ in range(n_samples)]\n",
    "    metrics_df_merged['src_idx'] = result\n",
    "    result = [num for num in range(len(test_sources)*len(tgtinds)) for _ in range(n_samples)]\n",
    "    test_metrics_df_merged['src_idx'] = result\n",
    "\n",
    "    metrics_df = metrics_df_merged\n",
    "    sources = sources_merged\n",
    "    mbr_matrices = mbr_matrices_merged\n",
    "    test_metrics_df = test_metrics_df_merged\n",
    "    test_sources = test_sources_merged\n",
    "    test_mbr_matrices = test_mbr_matrices_merged\n",
    "\n",
    "    n_examples = len(sources)\n",
    "    metric = 'comet'\n",
    "\n",
    "    critical_rate_comet, critical_n_lbd_comet = rerankers(metrics_df, sources, n_samples, n_examples, metric='comet', critical_threshold=1-threshold_dev)\n",
    "    critical_rate_cometkiwi, critical_n_lbd_cometkiwi = rerankers(metrics_df, sources, n_samples, n_examples, metric='cometkiwi', critical_threshold=1-threshold_dev)\n",
    "    critical_rate_random, critical_n_lbd_random = rerankers(metrics_df, sources, n_samples, n_examples, metric='random', critical_threshold=1-threshold_dev)\n",
    "\n",
    "    test_n_examples = len(test_sources)\n",
    "    test_critical_rate_comet, devtest_critical_n_lbd_comet = rerankers(test_metrics_df, test_sources, n_samples, test_n_examples, metric='comet', critical_threshold=1-threshold_devtest)\n",
    "    test_critical_rate_cometkiwi, devtest_critical_n_lbd_cometkiwi = rerankers(test_metrics_df, test_sources, n_samples, test_n_examples, metric='cometkiwi', critical_threshold=1-threshold_devtest)\n",
    "    test_critical_rate_random, devtest_critical_n_lbd_random = rerankers(test_metrics_df, test_sources, n_samples, test_n_examples, metric='random', critical_threshold=1-threshold_devtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mbr_scores(metrics_df, mbr_matrix, n_examples, n_samples):\n",
    "    for idx in range(n_examples):\n",
    "        chosen = torch.argmax(mbr_matrix[idx][:])\n",
    "        metrics_df[metrics_df['src_idx']==int(idx)].iloc[int(chosen)]\n",
    "        if idx == 0:\n",
    "            mbr_df = pd.DataFrame(metrics_df[metrics_df['src_idx']==int(idx)].iloc[int(chosen)]).transpose()\n",
    "        else:\n",
    "            mbr_df = pd.concat([mbr_df, pd.DataFrame(metrics_df[metrics_df['src_idx']==int(idx)].iloc[int(chosen)]).transpose()])\n",
    "    \n",
    "    mbr_df['n_samples'] = n_samples + 1\n",
    "    return mbr_df.mean()[\"comet\"], mbr_df\n",
    "\n",
    "n_examples = len(sources)\n",
    "mbr_scores_range = []\n",
    "mbr_df_range = []\n",
    "for i in range(n_samples):\n",
    "    mbr_score, mbr_df = get_mbr_scores(metrics_df, mbr_matrices[i], n_examples, i)\n",
    "    mbr_scores_range.append(mbr_score)\n",
    "    mbr_df_range.append(mbr_df)\n",
    "\n",
    "metrics_df_mbr = pd.concat(mbr_df_range, axis=0)\n",
    "metrics_df_mbr = metrics_df_mbr.sort_values(by=['src_idx', 'n_samples'])\n",
    "metrics_df_mbr\n",
    "\n",
    "test_n_examples = len(test_sources)\n",
    "test_mbr_scores_range = []\n",
    "test_mbr_df_range = []\n",
    "for i in range(n_samples):\n",
    "    test_mbr_score, test_mbr_df = get_mbr_scores(test_metrics_df, test_mbr_matrices[i], test_n_examples, i)\n",
    "    test_mbr_scores_range.append(test_mbr_score)\n",
    "    test_mbr_df_range.append(test_mbr_df)\n",
    "\n",
    "test_metrics_df_mbr = pd.concat(test_mbr_df_range, axis=0)\n",
    "test_metrics_df_mbr = test_metrics_df_mbr.sort_values(by=['src_idx', 'n_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbr_reranker(metrics_df_mbr, n_samples, n_examples, metric='comet', critical_threshold=0.7):\n",
    "\n",
    "    metrics_df_mbr['critical'] = np.where(metrics_df_mbr[metric] < critical_threshold, 1, 0)\n",
    "\n",
    "    critical_rate = []\n",
    "    critical_n_lbd = np.zeros((n_samples, n_examples))\n",
    "\n",
    "    for K in range(1, n_samples+1):\n",
    "        selected_df = metrics_df_mbr[metrics_df_mbr['n_samples']==K]\n",
    "        critical_rate.append(selected_df.mean()['critical'])\n",
    "\n",
    "        critical_n_lbd[K-1] = selected_df['critical']\n",
    "    \n",
    "    return critical_rate, critical_n_lbd\n",
    "\n",
    "critical_rate_mbr, critical_n_lbd_mbr = mbr_reranker(metrics_df_mbr, n_samples, n_examples, metric='comet', critical_threshold=1-threshold_dev)\n",
    "test_critical_rate_mbr, test_critical_n_lbd_mbr = mbr_reranker(test_metrics_df_mbr, n_samples, test_n_examples, metric='comet', critical_threshold=1-threshold_devtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Left: critical errors\n",
    "axes[0].plot(critical_rate_random, label=\"random\", color='g')\n",
    "axes[0].plot(critical_rate_cometkiwi, label=\"cometkiwi\", color='orange')\n",
    "axes[0].plot(critical_rate_mbr, label=\"MBR\", color='red')\n",
    "axes[0].plot(critical_rate_comet, label=\"comet\", color='blue')\n",
    "axes[0].plot(test_critical_rate_random, label=\"random (test)\", color='g', linestyle='dashed')\n",
    "axes[0].plot(test_critical_rate_cometkiwi, label=\"cometkiwi (test)\", color='orange', linestyle='dashed')\n",
    "axes[0].plot(test_critical_rate_mbr, label=\"MBR (test)\", color='red', linestyle='dashed')\n",
    "axes[0].plot(test_critical_rate_comet, label=\"comet (test)\", color='blue', linestyle='dashed')\n",
    "axes[0].set_xlabel(\"N\", fontsize=font_size)\n",
    "axes[0].set_ylabel(\"% critical errors\", fontsize=font_size)\n",
    "axes[0].set_title(\"% critical errors in the set\", fontsize=font_size)\n",
    "axes[0].tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "\n",
    "# Right: log critical errors\n",
    "axes[1].plot(np.log(critical_rate_random)-np.log(critical_rate_random)[0], label=\"Random\", color='g')\n",
    "axes[1].plot(np.log(critical_rate_cometkiwi)-np.log(critical_rate_cometkiwi)[0], label=\"Cometkiwi\",  color='orange')\n",
    "axes[1].plot(np.log(critical_rate_mbr)-np.log(critical_rate_mbr)[0], label=\"MBR\", color='red')\n",
    "axes[1].plot(np.log(critical_rate_comet)-np.log(critical_rate_comet)[0], label=\"Comet\", color='blue')\n",
    "axes[1].plot(np.log(test_critical_rate_random)-np.log(test_critical_rate_random)[0], label=\"random (test)\", color='g', linestyle='dashed')\n",
    "axes[1].plot(np.log(test_critical_rate_cometkiwi)-np.log(test_critical_rate_cometkiwi)[0], label=\"cometkiwi (test)\", color='orange', linestyle='dashed')\n",
    "axes[1].plot(np.log(test_critical_rate_mbr)-np.log(test_critical_rate_mbr)[0], label=\"MBR (test)\", color='red', linestyle='dashed')\n",
    "axes[1].plot(np.log(test_critical_rate_comet)-np.log(test_critical_rate_comet)[0], label=\"comet (test)\", color='blue', linestyle='dashed')\n",
    "axes[1].set_xlabel(\"N\", fontsize=font_size)\n",
    "axes[1].set_ylabel(\"log critical errors\", fontsize=font_size)\n",
    "axes[1].set_title(\"log critical errors in the set for different rerankers\", fontsize=font_size)\n",
    "axes[1].tick_params(axis='both', labelsize=ticks_size)\n",
    "axes[0].legend(loc='lower center', bbox_to_anchor=(1.1, -.5), fontsize=font_size, frameon=False, ncol=4)\n",
    "\n",
    "if merge_lps:\n",
    "    plt.suptitle(f'{srcind}-{tgtinds}, {temperature}, {top_p}, THR={threshold_dev}', y=1.05, fontsize=font_size)\n",
    "else:\n",
    "    plt.suptitle(f'{srcind}-{tgtind}, {temperature}, {top_p}, THR={threshold_dev}', y=1.05, fontsize=font_size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit reranking laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from entmax import sparsemax, entmax15, entmax_bisect\n",
    "from scipy.optimize import least_squares\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import gammaln, comb, logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_alpha_beta(p, n_samples_fit, y):\n",
    "    # p[0]= alpha, p[1]=beta\n",
    "    # y: ground truth\n",
    "    q=0\n",
    "    N = np.arange(1, n_samples_fit+1)\n",
    "    comet_log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            \n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)\n",
    "\n",
    "            somation_log =  np.log(comb(n, K)) + np.sum(np.log(p[0] + i_values_1 - 1)) + np.sum(np.log(p[1] + i_values_2 - 1)) - np.sum(np.log(p[0] + p[1] + i_values_3 - 1))\n",
    "            somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "        \n",
    "        result = somation\n",
    "        comet_log_failure_rate[i] = np.log(result)\n",
    "\n",
    "    eps = p[0]/(p[0]+p[1]) # eps = alpha/(alpha+beta)\n",
    "    expression_comet = comet_log_failure_rate - np.log(eps)\n",
    "    return expression_comet - y\n",
    "\n",
    "\n",
    "\n",
    "def fit_q_entmaxalpha(p, n_samples_fit, fitted_alpha, fitted_beta, y):\n",
    "\n",
    "    N = np.arange(1, n_samples_fit+1)\n",
    "    log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)            \n",
    "\n",
    "            x = torch.tensor((N[:n]) * np.log(p[0]))\n",
    "            results_entmax = []\n",
    "            expression_values_entmax = entmax_bisect(x, alpha=p[1]).tolist()\n",
    "            results_entmax.append(expression_values_entmax)\n",
    "            results_entmax = np.array(results_entmax)\n",
    "\n",
    "            somation_log =  np.log(comb(n, K)) + np.sum(np.log(fitted_alpha + i_values_1 - 1)) + np.sum(np.log(fitted_beta + i_values_2 - 1)) - np.sum(np.log(fitted_alpha + fitted_beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "            somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "        \n",
    "        result = somation\n",
    "        log_failure_rate[i] = np.log(result)\n",
    "    \n",
    "    eps = fitted_alpha/(fitted_alpha+fitted_beta) # eps = alpha/(alpha+beta)\n",
    "    expression_cometkiwi = log_failure_rate - np.log(eps)\n",
    "    \n",
    "    return expression_cometkiwi - y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_fit = int(5/5 * n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comet = (np.log(critical_rate_comet[:n_samples_fit]) - np.log(critical_rate_comet[0]))[:n_samples_fit]\n",
    "y_cometkiwi = (np.log(critical_rate_cometkiwi[:n_samples_fit]) - np.log(critical_rate_cometkiwi[0]))[:n_samples_fit]\n",
    "y_mbr = (np.log(critical_rate_mbr[:n_samples_fit]) - np.log(critical_rate_mbr[0]))[:n_samples_fit]\n",
    "\n",
    "p0 = np.zeros((2,))\n",
    "p0[0] = 1.0\n",
    "p0[1] = 1.0\n",
    "first_fit = least_squares(fit_alpha_beta, p0, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, y_comet), max_nfev=1000, bounds=([0.1,0.1],[1000,1000]))\n",
    "\n",
    "# cometkiwi\n",
    "p1 = np.zeros((2,))\n",
    "p1[0] = 0.1\n",
    "p1[1] = 0.75\n",
    "second_fit_cometkiwi = least_squares(fit_q_entmaxalpha, p1, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, first_fit.x[0], first_fit.x[1], y_cometkiwi), max_nfev=100, bounds=([0.001, 0.001],[1, 1]))\n",
    "\n",
    "# mbr\n",
    "p1 = np.zeros((2,))\n",
    "p1[0] = 0.1\n",
    "p1[1] = 0.75\n",
    "second_fit_mbr = least_squares(fit_q_entmaxalpha, p1, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, first_fit.x[0], first_fit.x[1], y_mbr), max_nfev=100, bounds=([0.001, 0.001],[1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "alpha = first_fit.x[0]\n",
    "beta = first_fit.x[1]\n",
    "eps = alpha / (alpha + beta)\n",
    "N = np.arange(1, n_samples+1)\n",
    "\n",
    "labels = ['qe', 'mbr', 'oracle']\n",
    "fitted_q_cometkiwi = second_fit_cometkiwi.x[0]\n",
    "entmax_alpha_cometkiwi = second_fit_cometkiwi.x[1]\n",
    "fitted_q_mbr = second_fit_mbr.x[0]\n",
    "entmax_alpha_mbr = second_fit_mbr.x[1]\n",
    "fitted_qs = [fitted_q_cometkiwi, fitted_q_mbr]\n",
    "entmax_alphas = [entmax_alpha_cometkiwi, entmax_alpha_mbr]\n",
    "\n",
    "q_values = [fitted_q_cometkiwi, fitted_q_mbr, 0]\n",
    "n_points = n_samples\n",
    "\n",
    "for q, color, entmax_alpha, label in zip(q_values, [colors[2], colors[3], colors[4]], [entmax_alpha_cometkiwi, entmax_alpha_mbr, 0], labels):\n",
    "    \n",
    "    log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)\n",
    "\n",
    "            if q!= 0:\n",
    "\n",
    "                x = torch.tensor((N[:n]) * np.log(q))\n",
    "                results_entmax = []\n",
    "                expression_values_entmax = entmax_bisect(x, alpha=entmax_alpha).tolist()\n",
    "                results_entmax.append(expression_values_entmax)\n",
    "                results_entmax = np.array(results_entmax)\n",
    "\n",
    "                somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "                somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "            else:\n",
    "                somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "\n",
    "        result = somation\n",
    "        log_failure_rate[i] = np.log(result)\n",
    "\n",
    "    if q!= 0:\n",
    "        plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='solid', label=label)\n",
    "    else:\n",
    "        plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='dashed', label=label)\n",
    "\n",
    "plt.scatter(N, np.log(test_critical_rate_cometkiwi) - np.log(test_critical_rate_cometkiwi[0]), color=colors[2], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(test_critical_rate_mbr) - np.log(test_critical_rate_mbr[0]), color=colors[3], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(test_critical_rate_comet[:n_points]) - np.log(test_critical_rate_comet[0]), color=colors[4], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.xlabel('$N$', fontsize=font_size)\n",
    "plt.ylabel('Log failure rate (wrt baseline)', fontsize=font_size)\n",
    "plt.legend(loc='upper right', fontsize=font_size, ncol=1)\n",
    "plt.yticks([-1.5, -1.0, -0.5, 0], fontsize=font_size)\n",
    "plt.xticks([0, 10, 20, 30, 40 ,50], fontsize=font_size)\n",
    "plt.tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "\n",
    "if tgtinds == ['pt-BR']:\n",
    "    plt.savefig('mt_pt-BR_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "elif tgtinds == ['es-LA']:\n",
    "    plt.savefig('mt_es-LA_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "elif tgtinds == ['ru']:\n",
    "    plt.savefig('mt_ru_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "else:\n",
    "    plt.savefig('mt_all_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "alpha = first_fit.x[0]\n",
    "beta = first_fit.x[1]\n",
    "eps = alpha / (alpha + beta)\n",
    "N = np.arange(1, n_samples+1)\n",
    "\n",
    "labels = ['qe', 'mbr', 'oracle']\n",
    "fitted_q_cometkiwi = second_fit_cometkiwi.x[0]\n",
    "entmax_alpha_cometkiwi = second_fit_cometkiwi.x[1]\n",
    "fitted_q_mbr = second_fit_mbr.x[0]\n",
    "entmax_alpha_mbr = second_fit_mbr.x[1]\n",
    "fitted_qs = [fitted_q_cometkiwi, fitted_q_mbr]\n",
    "entmax_alphas = [entmax_alpha_cometkiwi, entmax_alpha_mbr]\n",
    "\n",
    "q_values = [fitted_q_cometkiwi, fitted_q_mbr, 0]\n",
    "n_points = n_samples\n",
    "\n",
    "for q, color, entmax_alpha, label in zip(q_values, [colors[2], colors[3], colors[4]], [entmax_alpha_cometkiwi, entmax_alpha_mbr, 0], labels):\n",
    "    \n",
    "    log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)\n",
    "\n",
    "            if q!= 0:\n",
    "\n",
    "                x = torch.tensor((N[:n]) * np.log(q))\n",
    "                results_entmax = []\n",
    "                expression_values_entmax = entmax_bisect(x, alpha=entmax_alpha).tolist()\n",
    "                results_entmax.append(expression_values_entmax)\n",
    "                results_entmax = np.array(results_entmax)\n",
    "\n",
    "                somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "                somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "            else:\n",
    "                somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "\n",
    "        result = somation\n",
    "        log_failure_rate[i] = np.log(result)\n",
    "\n",
    "    if q!= 0:\n",
    "        plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='solid', label=label)\n",
    "    else:\n",
    "        plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='dashed', label=label)\n",
    "\n",
    "plt.scatter(N, np.log(critical_rate_cometkiwi) - np.log(critical_rate_cometkiwi[0]), color=colors[2], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(critical_rate_mbr) - np.log(critical_rate_mbr[0]), color=colors[3], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(critical_rate_comet[:n_points]) - np.log(critical_rate_comet[0]), color=colors[4], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.xlabel('$N$', fontsize=font_size)\n",
    "plt.ylabel('Log failure rate (wrt baseline)', fontsize=font_size)\n",
    "plt.legend(loc='upper right', fontsize=font_size, ncol=1)\n",
    "plt.yticks([-1.5, -1.0, -0.5, 0], fontsize=font_size)\n",
    "plt.xticks([0, 10, 20, 30, 40 ,50], fontsize=font_size)\n",
    "plt.tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "\n",
    "if tgtinds == ['pt-BR']:\n",
    "    plt.savefig('mt_dev_pt-BR_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "elif tgtinds == ['es-LA']:\n",
    "    plt.savefig('mt_dev_es-LA_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "elif tgtinds == ['ru']:\n",
    "    plt.savefig('mt_dev_ru_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "else:\n",
    "    plt.savefig('mt_dev_all_apred%.4f_bpred%.4f_cometkiwi_qpred%.4f_entpred%.4f_mbr_qpred%.4f_entpred%.4f.pdf' % (alpha,beta,fitted_q_cometkiwi,entmax_alpha_cometkiwi, fitted_q_mbr, entmax_alpha_mbr), bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values\n",
    "\n",
    "# pt\n",
    "alpha=0.1\n",
    "beta=0.4743\n",
    "fitted_q_cometkiwi = 0.0105\n",
    "entmax_alpha_cometkiwi = 0.001\n",
    "fitted_q_mbr = 0.001\n",
    "entmax_alpha_mbr = 0.1676\n",
    "\n",
    "# es\n",
    "alpha=0.1\n",
    "beta=0.4177\n",
    "fitted_q_cometkiwi = 0.0056\n",
    "entmax_alpha_cometkiwi = 0.001\n",
    "fitted_q_mbr = 0.001\n",
    "entmax_alpha_mbr = 0.1780\n",
    "\n",
    "# ru\n",
    "alpha=0.1\n",
    "beta=0.5011\n",
    "fitted_q_cometkiwi = 0.0014\n",
    "entmax_alpha_cometkiwi = 0.001\n",
    "fitted_q_mbr = 0.001\n",
    "entmax_alpha_mbr = 0.1971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
