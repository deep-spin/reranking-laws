{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "font_size = 18\n",
    "ticks_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'code-davinci-002'\n",
    "dataset_name = 'strategy_qa' #'svamp' \n",
    "dt = list(map(json.loads, open(f\"{model_name}/{dataset_name}/{dataset_name}_seed1.jsonl\")))\n",
    "dt_df = pd.DataFrame(dt)\n",
    "n_samples = len(dt_df.iloc[0].scores)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dt)):\n",
    "    if len(dt_df.iloc[0].scores) != n_samples:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dataframe\n",
    "expanded_rows = []\n",
    "for idx, row in dt_df.iterrows():\n",
    "    for i in range(n_samples):\n",
    "        expanded_row = {\n",
    "            'input': row['input'],\n",
    "            'generation': row['generation'][i],\n",
    "            'scores': row['scores'][i],\n",
    "            'answers': row['answers'][i],\n",
    "            'target': row['target'],\n",
    "            'probs': row['probs'][i],\n",
    "            'sample_idx': i,\n",
    "            'src_idx': idx\n",
    "        }\n",
    "        expanded_rows.append(expanded_row)\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "expanded_df['critical'] = expanded_df['scores'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "n_examples = len(dt_df)\n",
    "aux_1 = np.arange(1, n_samples+1)\n",
    "aux_2= np.tile(aux_1, n_examples)\n",
    "data_filtered = expanded_df.copy()\n",
    "data_filtered['sample_idx'] = aux_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerankers(data, n_samples, n_examples, metric, set):\n",
    "    \n",
    "    aux_1 = np.arange(1, n_samples+1)\n",
    "    aux_2= np.tile(aux_1, n_examples)\n",
    "\n",
    "    critical_n_lbd = np.full((n_samples, n_examples), -1)\n",
    "    for K in range(1, n_samples+1):\n",
    "        selected_df = data[data['sample_idx']<K+1]\n",
    "\n",
    "        if metric == 'oracle':\n",
    "            chosen_df = selected_df.loc[selected_df.groupby(selected_df.index // n_samples )['critical'].idxmin()]\n",
    "        \n",
    "        if metric == 'random':\n",
    "            chosen_df = selected_df[selected_df['sample_idx'] == K]\n",
    "        if metric == 'majority_voting':\n",
    "            indexes_to_keep = []\n",
    "            starting_at = 0\n",
    "            if set=='test':\n",
    "                if len(dt_df) % 2 != 0:\n",
    "                    starting_at=n_examples-1\n",
    "                else:\n",
    "                    starting_at=n_examples\n",
    "            for src_idx in range (starting_at, starting_at + n_examples):\n",
    "                mode_output = selected_df[selected_df['src_idx']==src_idx]['answers'].value_counts().idxmax()\n",
    "                selected_df_src = selected_df[selected_df['src_idx']==src_idx]\n",
    "                indexes = selected_df_src['answers'].index\n",
    "                for i in range(0,len(indexes)):\n",
    "                    if selected_df_src['answers'].iloc[i] == mode_output:\n",
    "                        break\n",
    "                indexes_to_keep.append(indexes[i])\n",
    "            chosen_df = selected_df.loc[indexes_to_keep]\n",
    "        critical_n_lbd[K-1] = np.array(chosen_df['critical'])\n",
    "    critical_absolute = critical_n_lbd.sum(axis=1)\n",
    "    critical_rate = critical_n_lbd.sum(axis=1)/n_examples\n",
    "    \n",
    "    return critical_absolute, critical_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_length = int(n_samples * int(n_examples/2))\n",
    "data_filtered_dev = data_filtered[:half_length]\n",
    "data_filtered_test = data_filtered[half_length:]\n",
    "\n",
    "metric = 'oracle'\n",
    "critical_absolute_oracle_dev, critical_rate_oracle_dev = rerankers(data_filtered_dev,  n_samples, int(len(data_filtered_dev)/n_samples), metric, 'dev')\n",
    "critical_absolute_oracle_test, critical_rate_oracle_test = rerankers(data_filtered_test,  n_samples, int(len(data_filtered_test)/n_samples), metric, 'test')\n",
    "\n",
    "metric = 'majority_voting'\n",
    "critical_absolute_maj_dev, critical_rate_maj_dev = rerankers(data_filtered_dev,  n_samples, int(len(data_filtered_dev)/n_samples), metric, 'dev')\n",
    "critical_absolute_maj_test, critical_rate_maj_test = rerankers(data_filtered_test,  n_samples, int(len(data_filtered_test)/n_samples), metric, 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Left: critical errors\n",
    "axes[0].plot(critical_rate_oracle_dev, label=\"oracle dev\", color='blue')\n",
    "axes[0].plot(critical_rate_maj_dev, label=\"maj dev\", color='red')\n",
    "axes[0].plot(critical_rate_oracle_test, label=\"oracle test\", color='blue', linestyle='dashed')\n",
    "axes[0].plot(critical_rate_maj_test, label=\"maj test\", color='red', linestyle='dashed')\n",
    "axes[0].set_xlabel(\"N\", fontsize=font_size)\n",
    "axes[0].set_ylabel(\"% critical errors\", fontsize=font_size)\n",
    "axes[0].set_title(\"% critical errors in the set\", fontsize=font_size)\n",
    "axes[0].tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "# Right: log critical errors\n",
    "axes[1].plot(np.log(critical_rate_oracle_dev)-np.log(critical_rate_oracle_dev)[0], label=\"oracle dev\", color='blue')\n",
    "axes[1].plot(np.log(critical_rate_maj_dev)-np.log(critical_rate_maj_dev)[0], label=\"maj dev\", color='red')\n",
    "axes[1].plot(np.log(critical_rate_oracle_test)-np.log(critical_rate_oracle_test)[0], label=\"oracle test\", color='blue', linestyle='dashed')\n",
    "axes[1].plot(np.log(critical_rate_maj_test)-np.log(critical_rate_maj_test)[0], label=\"maj test\", color='red', linestyle='dashed')\n",
    "axes[1].set_xlabel(\"N\", fontsize=font_size)\n",
    "axes[1].set_ylabel(\"log critical errors\", fontsize=font_size)\n",
    "axes[1].set_title(\"log critical errors in the set\", fontsize=font_size)\n",
    "axes[1].tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "axes[0].legend(loc='lower center', bbox_to_anchor=(1.1, -0.4), fontsize=font_size, frameon=False, ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit reranking laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from entmax import sparsemax, entmax15, entmax_bisect\n",
    "from scipy.optimize import least_squares\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import gammaln, comb, logsumexp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_beta_distribution(alpha, beta):\n",
    "    beta_lognorm = -gammaln(alpha+beta) + gammaln(alpha) + gammaln(beta)\n",
    "    return lambda tau: (alpha-1)*np.log(tau) + (beta-1)*np.log(1-tau) - beta_lognorm\n",
    "\n",
    "def integrate_expression(tau_start, tau_end):\n",
    "    result, _ = integrate.quad(lambda tau: expression(tau, N), tau_start, tau_end)\n",
    "    return result\n",
    "\n",
    "def fit_alpha_beta(p, n_samples_fit, y):\n",
    "    # p[0]= alpha, p[1]=beta\n",
    "    # y: ground truth\n",
    "    q=0\n",
    "    N = np.arange(1, n_samples_fit+1)\n",
    "    comet_log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            \n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)\n",
    "\n",
    "            somation_log =  np.log(comb(n, K)) + np.sum(np.log(p[0] + i_values_1 - 1)) + np.sum(np.log(p[1] + i_values_2 - 1)) - np.sum(np.log(p[0] + p[1] + i_values_3 - 1))\n",
    "            somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "        \n",
    "        result = somation\n",
    "        comet_log_failure_rate[i] = np.log(result)\n",
    "\n",
    "    eps = p[0]/(p[0]+p[1]) # eps = alpha/(alpha+beta)\n",
    "    expression_comet = comet_log_failure_rate - np.log(eps)\n",
    "    return expression_comet - y\n",
    "\n",
    "def fit_q_entmaxalpha(p, n_samples_fit, fitted_alpha, fitted_beta, y):\n",
    "\n",
    "    N = np.arange(1, n_samples_fit+1)\n",
    "    log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)            \n",
    "\n",
    "            x = torch.tensor((N[:n]) * np.log(p[0]))\n",
    "            results_entmax = []\n",
    "            expression_values_entmax = entmax_bisect(x, alpha=p[1]).tolist()\n",
    "            results_entmax.append(expression_values_entmax)\n",
    "            results_entmax = np.array(results_entmax)\n",
    "\n",
    "            somation_log =  np.log(comb(n, K)) + np.sum(np.log(fitted_alpha + i_values_1 - 1)) + np.sum(np.log(fitted_beta + i_values_2 - 1)) - np.sum(np.log(fitted_alpha + fitted_beta + i_values_3 - 1))\n",
    "            somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "        \n",
    "        result = somation\n",
    "        log_failure_rate[i] = np.log(result)\n",
    "    \n",
    "    eps = fitted_alpha/(fitted_alpha+fitted_beta) # eps = alpha/(alpha+beta)\n",
    "    expression_cometkiwi = log_failure_rate - np.log(eps)\n",
    "    \n",
    "    return expression_cometkiwi - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_fit = int(5/5 * n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comet = (np.log(critical_rate_oracle_dev[:n_samples_fit]) - np.log(critical_rate_oracle_dev[0]))[:n_samples_fit]\n",
    "y_mbr = (np.log(critical_rate_maj_dev[:n_samples_fit]) - np.log(critical_rate_maj_dev[0]))[:n_samples_fit]\n",
    "\n",
    "p0 = np.zeros((2,))\n",
    "p0[0] = 1.0\n",
    "p0[1] = 1.0\n",
    "first_fit = least_squares(fit_alpha_beta, p0, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, y_comet), max_nfev=1000, bounds=([0.1,0.1],[1000,1000]))\n",
    "\n",
    "p1 = np.zeros((2,))\n",
    "p1[0] = 0.1\n",
    "p1[1] = 0.75\n",
    "second_fit_mbr = least_squares(fit_q_entmaxalpha, p1, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, first_fit.x[0], first_fit.x[1], y_mbr), max_nfev=100, bounds=([0.001, 0.001],[1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "alpha = first_fit.x[0]\n",
    "beta = first_fit.x[1]\n",
    "eps = alpha / (alpha + beta)\n",
    "N = np.arange(1, n_samples+1)\n",
    "\n",
    "fitted_q_mbr = second_fit_mbr.x[0]\n",
    "entmax_alpha_mbr = second_fit_mbr.x[1]\n",
    "fitted_qs = [fitted_q_mbr]\n",
    "entmax_alphas = [entmax_alpha_mbr]\n",
    "labels = ['self-consistency', 'oracle']\n",
    "\n",
    "\n",
    "for fitted_q, entmax_alpha, color_reranker in zip(fitted_qs, entmax_alphas, ['red']):\n",
    "    q_values = [fitted_q, 0]\n",
    "    n_points = n_samples\n",
    "    for q, color, label in zip(q_values, [colors[3], colors[4]], labels):\n",
    "        log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "        for i, n in enumerate(N):\n",
    "            somation = 0\n",
    "            for K in range(n+1):\n",
    "                i_values_1 = np.arange(1, K + 1)\n",
    "                i_values_2 = np.arange(1, n - K + 1)\n",
    "                i_values_3 = np.arange(1, n+1)\n",
    "                t_values = np.arange(n-K+1, n+1)\n",
    "                j_values = np.arange(1, n+1)\n",
    "                if q!= 0:\n",
    "                    x = torch.tensor((N[:n]) * np.log(q))\n",
    "                    results_entmax = []\n",
    "                    expression_values_entmax = entmax_bisect(x, alpha=entmax_alpha).tolist()\n",
    "                    results_entmax.append(expression_values_entmax)\n",
    "                    results_entmax = np.array(results_entmax)\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "                    somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "                else:\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                    somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "            result = somation\n",
    "            log_failure_rate[i] = np.log(result)\n",
    "        if q!= 0:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='solid', label=label)\n",
    "        else:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='dashed', label=label)\n",
    "\n",
    "plt.scatter(N, np.log(critical_rate_maj_test) - np.log(critical_rate_maj_test[0]), color=colors[3], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(critical_rate_oracle_test[:n_points]) - np.log(critical_rate_oracle_test[0]), color=colors[4], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.xlabel('$N$', fontsize=font_size)\n",
    "plt.ylabel('Log failure rate (wrt baseline)', fontsize=font_size)\n",
    "plt.legend(loc='lower left', fontsize=font_size, ncol=1)\n",
    "plt.yticks([-6, -5, -4, -3, -2, -1, 0], fontsize=font_size)\n",
    "plt.xticks([0, 16, 32, 48, 64], fontsize=font_size)\n",
    "plt.tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "plt.savefig(f\"{model_name}_{dataset_name}_apred%.4f_bpred%.4f_qpred%.4f_entpred%.4f_.pdf\" % (alpha,beta,fitted_q,entmax_alpha), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted_q_mbr, entmax_alpha_mbr)\n",
    "print(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "eps = alpha / (alpha + beta)\n",
    "N = np.arange(1, n_samples+1)\n",
    "fitted_qs = [fitted_q_mbr]\n",
    "entmax_alphas = [entmax_alpha_mbr]\n",
    "labels = ['self-consistency', 'oracle']\n",
    "\n",
    "\n",
    "for fitted_q, entmax_alpha, color_reranker in zip(fitted_qs, entmax_alphas, ['red']):\n",
    "    q_values = [fitted_q, 0]\n",
    "    n_points = n_samples\n",
    "    for q, color, label in zip(q_values, [colors[3], colors[4]], labels):\n",
    "        log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "        for i, n in enumerate(N):\n",
    "            somation = 0\n",
    "            for K in range(n+1):\n",
    "                i_values_1 = np.arange(1, K + 1)\n",
    "                i_values_2 = np.arange(1, n - K + 1)\n",
    "                i_values_3 = np.arange(1, n+1)\n",
    "                t_values = np.arange(n-K+1, n+1)\n",
    "                j_values = np.arange(1, n+1)\n",
    "                if q!= 0:\n",
    "                    x = torch.tensor((N[:n]) * np.log(q))\n",
    "                    results_entmax = []\n",
    "                    expression_values_entmax = entmax_bisect(x, alpha=entmax_alpha).tolist()\n",
    "                    results_entmax.append(expression_values_entmax)\n",
    "                    results_entmax = np.array(results_entmax)\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "                    somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "                else:\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                    somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "            result = somation\n",
    "            log_failure_rate[i] = np.log(result)\n",
    "        if q!= 0:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='solid', label=label)\n",
    "        else:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='dashed', label=label)\n",
    "\n",
    "plt.scatter(N, np.log(critical_rate_maj_dev) - np.log(critical_rate_maj_dev[0]), color=colors[3], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(critical_rate_oracle_dev[:n_points]) - np.log(critical_rate_oracle_dev[0]), color=colors[4], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.xlabel('$N$', fontsize=font_size)\n",
    "plt.ylabel('Log failure rate (wrt baseline)', fontsize=font_size)\n",
    "plt.legend(loc='lower left', fontsize=font_size, ncol=1)\n",
    "plt.yticks([-6, -5, -4, -3, -2, -1, 0], fontsize=font_size)\n",
    "plt.xticks([0, 16, 32, 48, 64], fontsize=font_size)\n",
    "plt.tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "plt.savefig(f\"{model_name}_{dataset_name}_dev_apred%.4f_bpred%.4f_qpred%.4f_entpred%.4f_.pdf\" % (alpha,beta,fitted_q,entmax_alpha), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatproject",
   "language": "python",
   "name": "chatproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
