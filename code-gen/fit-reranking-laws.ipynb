{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "font_size = 18\n",
    "ticks_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"mbpp_deepseek-coder-7b-instruct-v1.5_temp_1.0_final_outputs.pkl\", 'rb')\n",
    "original_data= pickle.load(file)\n",
    "original_data = pd.DataFrame(original_data)\n",
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original_data.copy()\n",
    "data['ground_truth_test_1'] = ((data['result_unit_test_1'] == data['ground_truth_test_1']) |\n",
    "                               (pd.isna(data['result_unit_test_1']) & pd.isna(data['ground_truth_test_1'])))\n",
    "data['ground_truth_test_2'] = ((data['result_unit_test_2'] == data['ground_truth_test_2']) |\n",
    "                               (pd.isna(data['result_unit_test_2']) & pd.isna(data['ground_truth_test_2'])))\n",
    "data['ground_truth_test_3'] = ((data['result_unit_test_3'] == data['ground_truth_test_3']) |\n",
    "                               (pd.isna(data['result_unit_test_3']) & pd.isna(data['ground_truth_test_3'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add critical errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = True\n",
    "\n",
    "if all:\n",
    "    data_fixed = data\n",
    "    original_list = list(range(0, 399, 1))\n",
    "    result_list = [item for item in original_list for _ in range(200)]\n",
    "    data_fixed['src_idx'] = result_list\n",
    "    # Insert critical error when at least one of the ground truth tests is False\n",
    "    data_fixed['critical'] = np.where((data_fixed['ground_truth_test_1'] == False) |\n",
    "                                    (data_fixed['ground_truth_test_2'] == False) |\n",
    "                                    (data_fixed['ground_truth_test_3'] == False), 1, 0)\n",
    "    data_filtered = data_fixed\n",
    "    result_list = [item for item in original_list for _ in range(200)]\n",
    "    data_filtered['src_idx'] = result_list\n",
    "else:\n",
    "    data_fixed = data\n",
    "    original_list = list(range(0, 399, 1))\n",
    "    result_list = [item for item in original_list for _ in range(200)]\n",
    "    data_fixed['src_idx'] = result_list\n",
    "    data_fixed['critical'] = np.where(data_fixed['ground_truth_test_1'] == False, 1, 0)\n",
    "    data_filtered = data_fixed\n",
    "    result_list = [item for item in original_list for _ in range(200)]\n",
    "    data_filtered['src_idx'] = result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for all metrics below\n",
    "metric = 'random'\n",
    "metric = 'oracle'\n",
    "metric = 'majority_voting'\n",
    "\n",
    "n_samples=200\n",
    "n_examples=399\n",
    "aux_1 = np.arange(1, n_samples+1)\n",
    "aux_2= np.tile(aux_1, n_examples)\n",
    "data_filtered['n_sample'] = aux_2\n",
    "critical_n_lbd = np.full((n_samples, n_examples), -1)\n",
    "\n",
    "for K in range(1, n_samples+1):\n",
    "    selected_df = data_filtered[data_filtered['n_sample']<K+1]\n",
    "    if metric != 'random':\n",
    "        if metric == 'oracle':\n",
    "            chosen_df = selected_df.loc[selected_df.groupby(selected_df.index // n_samples )['critical'].idxmin()]\n",
    "        if metric == 'majority_voting':\n",
    "            indexes_to_keep = []\n",
    "            for src_idx in range (0, n_examples):\n",
    "                try: # this works if not all entries are failed\n",
    "                    mode_output = selected_df[selected_df['src_idx'] == src_idx]['result_unit_test_1'].loc[lambda x: x.astype(str).apply(lambda entry: not entry.startswith(\"failed\"))].value_counts().idxmax()\n",
    "                except:\n",
    "                    mode_output = selected_df[selected_df['src_idx']==src_idx]['result_unit_test_1'].value_counts().idxmax()\n",
    "                selected_df_src = selected_df[selected_df['src_idx']==src_idx]\n",
    "                indexes = selected_df_src['result_unit_test_1'].index\n",
    "                for i in range(0,len(indexes)):\n",
    "                    if selected_df_src['result_unit_test_1'].iloc[i] == mode_output:\n",
    "                        break\n",
    "                indexes_to_keep.append(indexes[i])\n",
    "            chosen_df = selected_df.loc[indexes_to_keep]\n",
    "    else:\n",
    "        chosen_df = data_filtered[data_filtered['n_sample'] == K]\n",
    "    critical_n_lbd[K-1] = np.array(chosen_df['critical'])\n",
    "\n",
    "critical_absolute = critical_n_lbd.sum(axis=1)\n",
    "critical_rate = critical_n_lbd.sum(axis=1)/n_examples\n",
    "\n",
    "if metric == 'oracle':\n",
    "    critical_absolute_oracle = critical_absolute\n",
    "    critical_rate_oracle = critical_rate\n",
    "if metric == 'majority_voting':\n",
    "    critical_absolute_maj = critical_absolute\n",
    "    critical_rate_maj = critical_rate\n",
    "if metric == 'random':\n",
    "    critical_absolute_random = critical_absolute\n",
    "    critical_rate_random = critical_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerankers(data, n_samples, n_examples, metric, set):\n",
    "    aux_1 = np.arange(1, n_samples+1)\n",
    "    aux_2= np.tile(aux_1, n_examples)\n",
    "    data['n_sample'] = aux_2\n",
    "    critical_n_lbd = np.full((n_samples, n_examples), -1)\n",
    "\n",
    "    for K in range(1, n_samples+1):\n",
    "        selected_df = data[data['n_sample']<K+1]\n",
    "        if metric != 'random':\n",
    "            if metric == 'oracle':\n",
    "                chosen_df = selected_df.loc[selected_df.groupby(selected_df.index // n_samples )['critical'].idxmin()]\n",
    "            if metric == 'majority_voting':\n",
    "                indexes_to_keep = []\n",
    "                starting_at = 0\n",
    "                if set=='test':\n",
    "                    starting_at=199\n",
    "                for src_idx in range (starting_at, starting_at + n_examples):\n",
    "                    try: # this works if not all entries are failed\n",
    "                        mode_output = selected_df[selected_df['src_idx'] == src_idx]['result_unit_test_1'].loc[lambda x: x.astype(str).apply(lambda entry: not entry.startswith(\"failed\"))].value_counts().idxmax()\n",
    "                    except:\n",
    "                        mode_output = selected_df[selected_df['src_idx']==src_idx]['result_unit_test_1'].value_counts().idxmax()\n",
    "                    selected_df_src = selected_df[selected_df['src_idx']==src_idx]\n",
    "                    indexes = selected_df_src['result_unit_test_1'].index\n",
    "                    for i in range(0,len(indexes)):\n",
    "                        if selected_df_src['result_unit_test_1'].iloc[i] == mode_output:\n",
    "                            break\n",
    "                    indexes_to_keep.append(indexes[i])\n",
    "                chosen_df = selected_df.loc[indexes_to_keep]\n",
    "        else:\n",
    "            chosen_df = data[data['n_sample'] == K]\n",
    "        critical_n_lbd[K-1] = np.array(chosen_df['critical'])\n",
    "\n",
    "    critical_absolute = critical_n_lbd.sum(axis=1)\n",
    "    critical_rate = critical_n_lbd.sum(axis=1)/n_examples\n",
    "    \n",
    "    return critical_absolute, critical_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=200\n",
    "n_examples=int(399/2)\n",
    "half_length = int(n_samples * n_examples)\n",
    "data_filtered_dev = data_filtered[:half_length]\n",
    "data_filtered_test = data_filtered[half_length:]\n",
    "\n",
    "metric = 'oracle'\n",
    "critical_absolute_oracle_dev, critical_rate_oracle_dev = rerankers(data_filtered_dev,  n_samples, n_examples, metric, 'dev')\n",
    "critical_absolute_oracle_test, critical_rate_oracle_test = rerankers(data_filtered_test,  n_samples, n_examples+1, metric, 'test')\n",
    "\n",
    "metric = 'majority_voting'\n",
    "critical_absolute_maj_dev, critical_rate_maj_dev = rerankers(data_filtered_dev,  n_samples, n_examples, metric, 'dev')\n",
    "critical_absolute_maj_test, critical_rate_maj_test = rerankers(data_filtered_test,  n_samples, n_examples+1, metric, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot 1: critical errors\n",
    "axes[0].plot(critical_rate_oracle_dev, label=\"oracle dev\", color='blue')\n",
    "axes[0].plot(critical_rate_maj_dev, label=\"maj dev\", color='red')\n",
    "axes[0].plot(critical_rate_oracle_test, label=\"oracle test\", color='blue', linestyle='dashed')\n",
    "axes[0].plot(critical_rate_maj_test, label=\"maj test\", color='red', linestyle='dashed')\n",
    "axes[0].set_xlabel(\"N\", fontsize=font_size)\n",
    "axes[0].set_ylabel(\"% critical errors\", fontsize=font_size)\n",
    "axes[0].set_title(\"% critical errors in the set\", fontsize=font_size)\n",
    "axes[0].tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "# Plot 2: log critical errors\n",
    "axes[1].plot(np.log(critical_rate_oracle_dev)-np.log(critical_rate_oracle_dev)[0], label=\"oracle dev\", color='blue')\n",
    "axes[1].plot(np.log(critical_rate_maj_dev)-np.log(critical_rate_maj_dev)[0], label=\"maj dev\", color='red')\n",
    "axes[1].plot(np.log(critical_rate_oracle_test)-np.log(critical_rate_oracle_test)[0], label=\"oracle test\", color='blue', linestyle='dashed')\n",
    "axes[1].plot(np.log(critical_rate_maj_test)-np.log(critical_rate_maj_test)[0], label=\"maj test\", color='red', linestyle='dashed')\n",
    "axes[1].set_xlabel(\"N\", fontsize=font_size)\n",
    "axes[1].set_ylabel(\"log critical errors\", fontsize=font_size)\n",
    "axes[1].set_title(\"log critical errors in the set\", fontsize=font_size)\n",
    "axes[1].tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "\n",
    "axes[0].legend(loc='lower center', bbox_to_anchor=(1.1, -0.4), fontsize=font_size, frameon=False, ncol=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting with least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "import math\n",
    "from entmax import sparsemax, entmax15, entmax_bisect\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import gammaln\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import comb\n",
    "from scipy.special import logsumexp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_beta_distribution(alpha, beta):\n",
    "    beta_lognorm = -gammaln(alpha+beta) + gammaln(alpha) + gammaln(beta)\n",
    "    return lambda tau: (alpha-1)*np.log(tau) + (beta-1)*np.log(1-tau) - beta_lognorm\n",
    "\n",
    "def integrate_expression(tau_start, tau_end):\n",
    "    result, _ = integrate.quad(lambda tau: expression(tau, N), tau_start, tau_end)\n",
    "    return result\n",
    "\n",
    "def fit_alpha_beta(p, n_samples_fit, y):\n",
    "    # p[0]= alpha, p[1]=beta\n",
    "    # y: ground truth\n",
    "\n",
    "    q=0\n",
    "    N = np.arange(1, n_samples_fit+1)\n",
    "    comet_log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)\n",
    "            somation_log =  np.log(comb(n, K)) + np.sum(np.log(p[0] + i_values_1 - 1)) + np.sum(np.log(p[1] + i_values_2 - 1)) - np.sum(np.log(p[0] + p[1] + i_values_3 - 1))\n",
    "            somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "        result = somation\n",
    "        comet_log_failure_rate[i] = np.log(result)\n",
    "\n",
    "    eps = p[0]/(p[0]+p[1]) # eps = alpha/(alpha+beta)\n",
    "    expression_comet = comet_log_failure_rate - np.log(eps)\n",
    "    return expression_comet - y\n",
    "\n",
    "\n",
    "def fit_q_entmaxalpha(p, n_samples_fit, fitted_alpha, fitted_beta, y):\n",
    "\n",
    "    N = np.arange(1, n_samples_fit+1)\n",
    "    log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "\n",
    "    for i, n in enumerate(N):\n",
    "        somation = 0\n",
    "        for K in range(n+1):\n",
    "            i_values_1 = np.arange(1, K + 1)\n",
    "            i_values_2 = np.arange(1, n - K + 1)\n",
    "            i_values_3 = np.arange(1, n+1)\n",
    "            t_values = np.arange(n-K+1, n+1)\n",
    "            j_values = np.arange(1, n+1)            \n",
    "            x = torch.tensor((N[:n]) * np.log(p[0]))\n",
    "            results_entmax = []\n",
    "            expression_values_entmax = entmax_bisect(x, alpha=p[1]).tolist()\n",
    "            results_entmax.append(expression_values_entmax)\n",
    "            results_entmax = np.array(results_entmax)\n",
    "            somation_log =  np.log(comb(n, K)) + np.sum(np.log(fitted_alpha + i_values_1 - 1)) + np.sum(np.log(fitted_beta + i_values_2 - 1)) - np.sum(np.log(fitted_alpha + fitted_beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "            somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "        result = somation\n",
    "        log_failure_rate[i] = np.log(result)\n",
    "    \n",
    "    eps = fitted_alpha/(fitted_alpha+fitted_beta) # eps = alpha/(alpha+beta)\n",
    "    expression_cometkiwi = log_failure_rate - np.log(eps)\n",
    "    \n",
    "    return expression_cometkiwi - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_fit = int(5/5 * n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comet = (np.log(critical_rate_oracle_dev[:n_samples_fit]) - np.log(critical_rate_oracle_dev[0]))[:n_samples_fit]\n",
    "y_mbr = (np.log(critical_rate_maj_dev[:n_samples_fit]) - np.log(critical_rate_maj_dev[0]))[:n_samples_fit]\n",
    "\n",
    "p0 = np.zeros((2,))\n",
    "p0[0] = 1.0\n",
    "p0[1] = 1.0\n",
    "\n",
    "first_fit = least_squares(fit_alpha_beta, p0, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, y_comet), max_nfev=1000, bounds=([0.1,0.1],[1000,1000]))\n",
    "\n",
    "p1 = np.zeros((2,))\n",
    "p1[0] = 0.1\n",
    "p1[1] = 0.75\n",
    "second_fit_mbr = least_squares(fit_q_entmaxalpha, p1, loss='soft_l1', f_scale=1.0, args=(n_samples_fit, first_fit.x[0], first_fit.x[1], y_mbr), max_nfev=100, bounds=([0.001, 0.001],[1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "labels = ['majority voting', 'oracle']\n",
    "\n",
    "alpha = first_fit.x[0]\n",
    "beta = first_fit.x[1]\n",
    "eps = alpha / (alpha + beta)\n",
    "N = np.arange(1, n_samples+1)\n",
    "fitted_q_mbr = second_fit_mbr.x[0]\n",
    "entmax_alpha_mbr = second_fit_mbr.x[1]\n",
    "fitted_qs = [fitted_q_mbr]\n",
    "entmax_alphas = [entmax_alpha_mbr]\n",
    "\n",
    "for fitted_q, entmax_alpha, color_reranker in zip(fitted_qs, entmax_alphas, ['red']):\n",
    "    q_values = [fitted_q, 0]\n",
    "    n_points = n_samples\n",
    "\n",
    "    for q, color, label in zip(q_values, [colors[3], colors[4]], labels):\n",
    "        \n",
    "        log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "        \n",
    "        for i, n in enumerate(N):\n",
    "            somation = 0\n",
    "            for K in range(n+1):\n",
    "                i_values_1 = np.arange(1, K + 1)\n",
    "                i_values_2 = np.arange(1, n - K + 1)\n",
    "                i_values_3 = np.arange(1, n+1)\n",
    "                t_values = np.arange(n-K+1, n+1)\n",
    "                j_values = np.arange(1, n+1)\n",
    "                if q!= 0:\n",
    "                    x = torch.tensor((N[:n]) * np.log(q))\n",
    "                    results_entmax = []\n",
    "                    expression_values_entmax = entmax_bisect(x, alpha=entmax_alpha).tolist()\n",
    "                    results_entmax.append(expression_values_entmax)\n",
    "                    results_entmax = np.array(results_entmax)\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                    somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "                else:\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                    somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "\n",
    "            result = somation\n",
    "            log_failure_rate[i] = np.log(result)\n",
    "\n",
    "        if q!= 0:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='solid', label=label)\n",
    "        else:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='dashed', label=label)\n",
    "\n",
    "\n",
    "plt.scatter(N, np.log(critical_rate_maj_test) - np.log(critical_rate_maj_test[0]), color=colors[3], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(critical_rate_oracle_test[:n_points]) - np.log(critical_rate_oracle_test[0]), color=colors[4], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.xlabel('$N$', fontsize=font_size)\n",
    "plt.ylabel('Log failure rate (wrt baseline)', fontsize=font_size)\n",
    "plt.legend(loc='upper right', fontsize=font_size, ncol=1)\n",
    "plt.yticks([-1.5, -1.0, -0.5, 0], fontsize=font_size)\n",
    "plt.xticks([0, 50, 100, 150, 200], fontsize=font_size)\n",
    "plt.tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "plt.savefig('temp1.0_alltests_codegen_apred%.4f_bpred%.4f_qpred%.4f_entpred%.4f_.pdf' % (alpha,beta,fitted_q,entmax_alpha), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted_q_mbr, entmax_alpha_mbr)\n",
    "print(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "labels = ['majority voting', 'oracle']\n",
    "eps = alpha / (alpha + beta)\n",
    "N = np.arange(1, n_samples+1)\n",
    "fitted_qs = [fitted_q_mbr]\n",
    "entmax_alphas = [entmax_alpha_mbr]\n",
    "\n",
    "for fitted_q, entmax_alpha, color_reranker in zip(fitted_qs, entmax_alphas, ['red']):\n",
    "    q_values = [fitted_q, 0]\n",
    "    n_points = n_samples\n",
    "\n",
    "    for q, color, label in zip(q_values, [colors[3], colors[4]], labels):\n",
    "        \n",
    "        log_failure_rate = np.zeros_like(N, dtype=float)\n",
    "        \n",
    "        for i, n in enumerate(N):\n",
    "            somation = 0\n",
    "            for K in range(n+1):\n",
    "                i_values_1 = np.arange(1, K + 1)\n",
    "                i_values_2 = np.arange(1, n - K + 1)\n",
    "                i_values_3 = np.arange(1, n+1)\n",
    "                t_values = np.arange(n-K+1, n+1)\n",
    "                j_values = np.arange(1, n+1)\n",
    "                if q!= 0:\n",
    "                    x = torch.tensor((N[:n]) * np.log(q))\n",
    "                    results_entmax = []\n",
    "                    expression_values_entmax = entmax_bisect(x, alpha=entmax_alpha).tolist()\n",
    "                    results_entmax.append(expression_values_entmax)\n",
    "                    results_entmax = np.array(results_entmax)\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1)) #+ np.log(np.sum(q**(t_values-1))) - np.log(np.sum(q**(j_values-1)))\n",
    "                    somation += np.exp(somation_log) * results_entmax[0][n-K:n].sum()\n",
    "                else:\n",
    "                    somation_log =  np.log(comb(n, K)) + np.sum(np.log(alpha + i_values_1 - 1)) + np.sum(np.log(beta + i_values_2 - 1)) - np.sum(np.log(alpha + beta + i_values_3 - 1))\n",
    "                    somation += np.exp(somation_log)*np.sum(q**(t_values-1)) / np.sum(q**(j_values-1))\n",
    "            result = somation\n",
    "            log_failure_rate[i] = np.log(result)\n",
    "\n",
    "        if q!= 0:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='solid', label=label)\n",
    "        else:\n",
    "            plt.plot(N, log_failure_rate - np.log(eps), color=color, linewidth=4.0, linestyle='dashed', label=label)\n",
    "\n",
    "plt.scatter(N, np.log(critical_rate_maj_dev) - np.log(critical_rate_maj_dev[0]), color=colors[3], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.scatter(N, np.log(critical_rate_oracle_dev[:n_points]) - np.log(critical_rate_oracle_dev[0]), color=colors[4], marker='o', s=.5 * (plt.rcParams['lines.markersize'] ** 2))\n",
    "plt.xlabel('$N$', fontsize=font_size)\n",
    "plt.ylabel('Log failure rate (wrt baseline)', fontsize=font_size)\n",
    "plt.legend(loc='upper right', fontsize=font_size, ncol=1)\n",
    "plt.yticks([-1.5, -1.0, -0.5, 0], fontsize=font_size)\n",
    "plt.xticks([0, 50, 100, 150, 200], fontsize=font_size)\n",
    "plt.tick_params(axis='both', labelsize=ticks_size)\n",
    "\n",
    "plt.savefig('temp1.0_alltests_codegen_dev_apred%.4f_bpred%.4f_qpred%.4f_entpred%.4f_.pdf' % (alpha,beta,fitted_q,entmax_alpha), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatproject",
   "language": "python",
   "name": "chatproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
